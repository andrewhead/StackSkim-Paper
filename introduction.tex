\section{Introduction}

Programmers often rely on online tutorials to pick up new skills and learn how to use frameworks and libraries.
This is an element of programmers' tendency to engage in interleaved programming and information foraging during programming tasks~\cite{brandt_two_2009}~\cite{brandt_example-centric_2010}.
However, online walkthroughs often contain errors or incomplete information.
In the authors' experiences, they can lead to errors and fail to provide the conceptual knowledge the programmer will need to extend online code to their own tasks.
In the best case, this can cause a brief interruption in programming productivity.
In worse cases, it can cause frustration and confusion to the point of needlessly discouraging programming learners from learning new skills.

Tutorials often mark an introduction to new concepts and hands-on practice with the tools that help programmers become comfortable performing new tasks.
Unfortunately, even the best written tutorials have pitfalls.
They can't explain everything that the minimally-experienced user doesn't know, as they should maintain conciseness for more experienced readers and for a focus on the primary task at hand.
Given the multi-domain focus of some tutorials, most readers may come from a background that requires them to consult outside documentation.
A tutorial that walks one through a web scraping task may require an understanding of the Python language, callbacks, CSS selectors, regular expressions, and threading.
Gaining an understanding of any one of these prerequisites can be time-consuming, particularly if the programmer doesn't know the vocabulary of the domain~\cite{furnas_vocabulary_1987}. \marti{Even harder to grasp references to concepts like threads and processes if you don't know what they are when reading the tutorial.}

API method descriptions may be too abstract or vague to offer immediate understanding of unknown syntax or libraries.
Introductory documentation in a new domain may take too long to walk through to learn a supplemental skill to a primary task.

We attempt to build a \emph{new paradigm of programming documentation} between API descriptions and detailed, manually crafted walkthroughs.
In this paper, we propose \emph{\Glspl{name}, which are on-demand, context-relevant descriptions of programming grammars, commands and libraries} designed to be inserted within an existing tutorial to clarify the content of the tutorial, in a manner tailored to the reader's background knowledge.

\begin{figure}[!t]
\centering{
    \subfigure[Text augmentation explaining a CSS selector]{
        \framebox{\includegraphics[width=.4\textwidth]{figures/css_explanation}}
        \label{fig:css_explanation}
    }
    \subfigure[Visualization and demonstration of regular expression]{
        \framebox{\includegraphics[width=.4\textwidth]{figures/regex_explanation}}
        \label{fig:regex_explanation}
    }
}
\label{fig:tutorons}
\caption{Automatic, context-relevant textual and visual explanations of code generated by descriptive \glspl{name}.}
\end{figure}

Automatic, context-relevant descriptions can take many forms, ranging from simple text descriptions to code fragments to visualizations. 
We demonstrate how \glspl{name} of diverse types can produce just-in-time clarifications tailored to the domain and the communicative goal.
In particular, we consider \glspl{name} that can:
\begin{itemize} \itemsep1pt
\item generate text descriptions at multiple levels of detail
\item create domain-specific visualizations of code models
\item produce context-relevant usage examples
\item reinforce and clarify concepts from other \glspl{name}.
\end{itemize}

Ultimately, we believe \glspl{name} can speed up the process of interleaved web search for knowledge and code and implementation in the personal development environment~\cite{brandt} by reducing the number of resources programmers have to access to understand a central walkthrough.
\Glspl{name} can aid in such an ecosystem in three ways: tutorial reading, tutorial production, and code comprehension.
Through early user interface prototypes, we demonstrate how \glspl{name} will integrate into typical programming information seeking and coding practices.
We discuss the implications of this style of documentation for those writing programming documentation, highlighting the additional efforts needed and a sustainable framework for developing suites of context-relevant, on-demand comments.
To justify some of these expectations, we perform a preliminary evaluation to discover user perceptions of the helpfulness and relevance of \gls{name}-generated annotations.
We also work with a major API documentation developer to assess the paradigm shifts and effort needed to build a \gls{name} for a mainstream API.

\subsection{Motivation}

Why do we need to help people seek information?
Programmers encounter problems reusing material online (Figure~\ref{fig:bad_tutorials}), that lead us to believe that tutorials should provide better support to:
\begin{itemize} \itemsep1pt
\item Help users recognize and overcome errors
\item Provide knowledge of best practices
\item Develop users' conceptual knowledge of their toolsets
\end{itemize}
Note that these are related to the tasks that Carroll describes in minimal instruction theory.

\begin{figure*}[t]
\centering{
    \subfigure[The author of this tutorial assumes that readers of the tutorial are already literate in reading CSS selectors such as \texttt{div.foo li a}.]{
        \framebox{\includegraphics[width=.9\textwidth]{figures/css_bad}}
        \label{fig:css_bad}
    }
    \subfigure[The CascadeClassifer caused the paper's first author a great deal of grief in a past project due to the constructor's silent failure.  This caused him to experience an understanding barrier that could be avoided through a cv2-specific tutoron.]{
        \framebox{\includegraphics[width=.9\textwidth]{figures/cascadeclassifier_bad}}
        \label{fig:cascadeclassifier_bad}
    }
    \subfigure[A demonstration of scraping the web with \texttt{wget}.  Additional information on rate limiting could be helpful here to the eager tutorial learner who will instantly apply this technique.\bjoern{An interesting difference here is that you describe information that is NOT present in the command line. It strikes me as a harder problem to look for *absences* of code and determine whether this would be a good place to add it.}]{
        \framebox{\includegraphics[width=.9\textwidth]{figures/wget_bad}}
        \label{fig:so_wget_bad}
    }
}
\caption{Three examples of online tutorials that can cause grief when followed.}
\label{fig:bad_tutorials}
\end{figure*}

\subsection{Background}

\subsubsection{How to Write Usable Technical Documentation}

We are inspired by minimal instruction theory, which provides guidelines for developing usable technical documentation~\cite{carroll_nurnberg_1990}.
There are three main insights of the minimalist approach:
learners are allowed to start immediatedly on meaningfully realistic tasks,
the amount of reading and other passive activity in training is reduced,
and errors and error recovery are presented in a way to make them less traumatic and more pedagogically productive.
Interstingly, today we find ourselves at a point where that much of the typical programming documentation is no longer developed by professionals.
Programmers increasingly use \emph{crowd documentation}~\cite{parnin_measuring_2011} found on the web that may be written by hobbyists without formal training writing usable documentation and who do not have QA resources to cross-check documents' quality.
\andrew{Is this the right reference for the term crowd documentation?}

When it is not possible to produce minimal instruction that has been iteratively tested and tailored to its audience, Farkas recommends \emph{layered documentation}~\cite{farkas_layering_1998}.
Layered documentation allows users to access more \emph{backup information} for tasks like error recognition and correction, and enables the same documentation to be used by readers from different backgrounds.
We position our work with the core belief that minimal instruction is a worthwhile but likely unattainable standard for online programming tutorials.
Given the diverse audiences of programming tutorials and the lack of documentation expertise of their authors, minimal instruction seems impossible to achieve.
We therefore adapt Farkas's advice with a technique for adding interactive layering to existing tutorial documentation on the web.
Through this, we approach the aims of minimal instruction: improved transfer of tutorial skills to personal tasks, less web search for discovering background knowledge, and faster error recovery.

Eiriksdottir \& Catrambone~\cite{eiriksdottir_procedural_2011} detail three types of instructions --- procedures, principles, and examples --- and their pedagogical aims.
Detailed procedures and relevant examples are likely to ease users' initial task performance.
More abstract procedures promote good learning and transfer.
We believe that \glspl{name} can improve relevance of more general procedures by providing just-in-time description of configurable parameters of APIs.
Furthermore, they can be used to describe relevant principles and interactive examples to aid transfer beyond the current task.

\subsubsection{What are the strengths and weaknesses of today's tutorials?}

Lafreniere et al.~\cite{lafreniere_understanding_2013} determined the type of activites that users engage in through comment-based discussion following the body of tutorials.
\andrew{What were the activities, how do people learn from tutorials, what are their weaknesses?}
In the programming domain, Parnin \& Treude~\cite{parnin_measuring_2011} find that 87.4\% of the methods of the jQuery API are described by a blog post in the first 10 web search results.
Of these blog posts, about half were tutorials.

In a survey of 154 Photoshop tutorials, Lount \& Bunt~\cite{lount_characterizing_2014} harvested tutorials from an application-centered community, tutorial aggregator, tutorial factory, and popular tutorials via the CUTS tecnique~\cite{fourney_characterizing_2011}.
Among other findings, Lount \& Bunt describe strengths and weaknesses of the corpus as a whole.
Almost all tutorials included source files (90.3\%), the initial image (91.6\%), final image (96.7\%), at least one image per step (84.4\%), and references to past steps when repeated steps were used (89.6\%).
However, 40.7\% of tutorials contained no attempts to address potential errors, 83.1\% omitted any version information, and only 1 of every 20 steps had any explanation.
Mechanisms to improve such tutorials' coverage of potential efforts and explanation of tools used could improve the quality of the average online tutorial.

\andrew{Also possibly relevant:~\cite{ames_just_2001}, for when and how to intervene with instructions.}


