\section{Preliminary Study}

\andrew{
A past version of this section with preliminary, informal interviews mentioned pitfalls using wild code:
unexpected runtime consequences, unclear instructions, version problems, red herrings finding bugs, code that doesn't follow best practices.
The past version also described frequency of use of different types of materials online, but was only collected for 5-10 programmers with wildly different programming backgrounds.
Probably that should be replaced with a larger-scale study.
Most of these findings have come from preliminary interviews.
These should be replaced with findings from official formative interviews and studies.
}

We preform a study where we show $N=20$ programmers popular tutorials in a language they are familiar with.
We show each programmer 10 tutorials and ask them to mark 3 locations in the tutorial where they want more information.
We could do this through Amazon Mechanical Turk, some free-lancing site, or maybe even with an programming learning community online (MOOC classroom) to know the current stage of experience of the users and have them complete the experiment online.

We end up with about 600 marked sections in tutorials of where additional clarification would be helpful.
We determine how many of the marked sections overlap with another request in a different tutorial and the tools, APIs and components that programmers want to learn more about.
