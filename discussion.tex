\section{Discussion}

%%\subsubsection{Evaluating Usability of \Glspl{exp} Interactions}

%%Programmers access \glspl{exp} by selecting code fragments on the page that they want to have explained.
%%In addition, we noted that many of the users selected text when walking through the code during think aloud.
%%Three participants selected code in tasks where \glspl{exp} were disabled when describing either thinking about the code or describing it to the study proctor ($P2$, $P4$, $P5$).
%%One subject even inadvertently brought up an \gls{exp} while pointing out code to the proctor ($P1$).
%%We believe that for some participants, activating the \glspl{exp} by selecting text became a natural, instinctual action.
%%In the final wget task, on subject selected text for a flag he didn't know before remembering that \glspl{exp} were turned off for the task ($P5$).
%%Many participants tried to activate \glspl{exp} to describe single arguments of wget commands ($P2$, $P3$, $P4$, $P5$).
%%This worked in their cases, as there was only ever one code snippet on the page to be explained, and the substring they chose matched the explainable code fragment according to our selection algorithm.

%%However, the leniency of our algorithm for matching a text selection to an explained code fragment caused confusion for programmers about what fragments would be explained on each page ($P1$, $P2$, $P5$).
%%For the same reason, explanations generated did not always match the fragment selected ($P1$, $P3$, $P5$).
%%For example, one user selected the text \texttt{<p>} for which no explanation was generated by the explanation server, as no CSS selector starts with a less-than sign.
%%However, our selection matching algorithm matched this string to the \texttt{p.mainPageMeters} selector for which an explanation \emph{had} been generated by the server.
%%As a result, this user viewed an irrelevant explanation for the code fragment he was viewing ($P5$).

\subsection{Study Caveats}

We are encouraged by the results of this preliminary evaluation of the \gls{exp} idea of context-sensitive programming explanations.
Participants were able to complete the tasks in most cases without requiring other documentation, whereas participants without the explanatory helper text needed to consult external resources.
That said, the study had several limitations.  It consisted of only a small number of participants, and the tasks were designed such that the \glspl{name} would function properly. 

Furthermore participants may have been more patient with \gls{exp} content than they would have been with documentation they found on their own, especially if they assumed \glspl{exp} code snippets were selected to provide critical insight.
Programmers may not take the same care in real-world scenarios in reading the \gls{exp} text as they did in the study.

Finally, tasks in the study involved edit or deletion tasks with existing code.
\Glspl{name} will have to be augmented before they can provide insights for additive tasks that can suggest relevant code options that are not described in the code itself.

\subsection{Future Work}

\begin{changes}
\shortchange{On a web where a \gls{name} exists for every cryptic language, what explanations do programmers see when an example is detected and explained by multiple \glspl{name}?}
First, we expect that in future versions, programmers can manage languages and libraries they want to have explained from a configuration interface for the addon, perhaps from the browser toolbar.
Second, we propose ranking explanations by the `likeliness' that an explainable region belongs to the detected language.
We are currently investigating the use of both rule-based and learned weights based on the frequency of characteristic node types in parse trees as a way of generating thes `likeliness' ratings.
\end{changes}

\begin{changes}
In our experience, building reliable detectors requires iterative development and evaluation with a core set of tutorials that use a language.
Collecting a set of test documents, developing the detector, reappropriating parser code, and implmenting an explainer can take dozens of hours.
As the number of languages for which tutorons would be useful is likely in the dozens, such investments could be appropriate for dedicated members of the larger programmer community, rather than programmers looking for a weekend project.
\end{changes}

We are also interested in conducting a study with novice programmers.
We believe that observing the problem-solving strategies of novice programmers will yield better recommendations for how to design in-situ help for this group.
